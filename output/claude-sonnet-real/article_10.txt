We present <model>PaLM-2</model>, a large-scale transformer-based language model developed in the <country>United States</country> and released in <year>2023</year>. Our model incorporates several architectural improvements over previous iterations, including enhanced attention mechanisms and optimized layer normalization techniques. The model comprises <params>340 billion parameters</params>, positioning it among the largest publicly documented language models to date. The architecture follows the standard decoder-only transformer design with modifications to improve training stability and inference efficiency.

The training process was conducted on Google's custom <hardware>TPU v4</hardware> infrastructure, leveraging the high memory bandwidth and specialized matrix multiplication units optimized for transformer computations. The distributed training setup utilized 4,096 TPU v4 chips arranged in a pod configuration, enabling efficient gradient synchronization and parameter updates across the massive model. The training corpus consisted of multilingual text data spanning web documents, books, academic papers, and code repositories, totaling approximately 3.6 trillion tokens after deduplication and filtering.

The complete training process required <training>3.2 months</training> of continuous computation, consuming approximately 2.5 million TPU v4 hours. We employed a modified AdamW optimizer with a peak learning rate of 1e-4 and implemented gradient clipping to prevent training instabilities. The training schedule included a warm-up phase of 10,000 steps followed by cosine decay scheduling. Intermediate checkpoints were saved every 1,000 steps to enable recovery from potential hardware failures and facilitate ablation studies on partially trained models.

Evaluation results demonstrate significant improvements over previous models across multiple benchmarks, including a 15.3% improvement on MMLU and 12.7% on HellaSwag compared to our previous iteration. The model shows particularly strong performance on reasoning tasks and multilingual understanding, with notable gains in low-resource languages. These improvements can be attributed to the combination of increased model scale, enhanced training data quality, and architectural refinements implemented during the development process.