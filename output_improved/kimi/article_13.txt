Our implementation of <model>Google-UL2-20B</model> follows the encoder-decoder architecture with mixture-of-denoisers pre-training objectives. The model was trained on the C4 corpus augmented with 750GB of filtered web text and scientific articles. We utilized a <gpu_count>256</gpu_count> <hardware>TPU v4 pod</hardware> configuration with data parallelism across 128 hosts and model sharding within each host. The training employed a batch size of 2048 sequences with 512 tokens per sequence, totaling approximately 1 million tokens per step. We adopted the Adafactor optimizer with a learning rate schedule that linearly increases to 1e-3 over 10,000 steps and then decays with inverse square root. The model incorporates 32 transformer layers with hidden dimension 6144 and 32 attention heads. Training was conducted over 1.2 trillion tokens with extensive evaluation on downstream tasks including SuperGLUE, XTREME, and Big-Bench. The final checkpoint was released in <year>2022</year> after 4 weeks of training and demonstrates strong few-shot learning capabilities across diverse NLP benchmarks.