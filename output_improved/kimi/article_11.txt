We implemented the proposed architecture by extending the Swin-Transformer backbone with deformable attention modules for improved feature extraction on high-resolution satellite imagery. Training was conducted on <hardware>NVIDIA H100 80GB GPUs</hardware> distributed across multiple nodes, with each GPU processing a micro-batch of 16 images. The dataset comprised 3.7TB of multi-spectral imagery collected from Sentinel-2 satellites between 2020-2023, preprocessed using standard atmospheric correction and cloud masking techniques. We employed mixed-precision training with automatic mixed precision (AMP) to optimize memory usage, achieving a throughput of 2,500 images per second during peak performance. The optimization used AdamW with β₁=0.9, β₂=0.999, weight decay of 0.05, and a one-cycle learning rate schedule peaking at 2e-3. Gradient clipping was set to 1.0 to stabilize training. Data augmentation included random rotation, color jittering, and multi-scale training with patch sizes ranging from 224×224 to 896×896 pixels. The total training duration spanned <training>approximately 12 days</training>, with validation performed every 2,000 steps. We evaluated the model on the BigEarthNet benchmark, achieving 87.3% mAP for multi-label classification across 43 land cover categories, outperforming the previous state-of-the-art by 3.2 percentage points.