We conducted all experiments on the <hardware>NVIDIA H100 80GB GPUs</hardware>, leveraging FP16 mixed precision and activation checkpointing to accommodate the high-resolution inputs. Training spanned <training>approximately six weeks</training> with a cosine learning-rate schedule that decayed from 5e-4 to 1e-6, warmed up over the first 5 % of iterations, and was coupled with a global batch size of 2048 images. The dataset was assembled by scraping 2.3 M high-resolution aerial scenes from NAIP archives at 60 cm ground-sample distance, cropped into 1024×1024 tiles, and augmented with random horizontal flips, color-jitter (±0.4), and CutMix. Optimization employed LAMB with β1=0.9, β2=0.999, weight-decay 0.02, and gradient-clipping at 1.0; EMA with decay 0.9999 was maintained for evaluation. Every 10 k steps we ran on-the-fly k-means over the latent codes to refresh the codebook, which stabilized vector-quantization perplexity below 5.5. All infrastructure sat in our Oregon data-center, drawing ≈ 85 kW peak power and requiring nightly temperature throttling to keep junctions below 83 °C.