To stabilize policy updates in high-dimensional continuous control, we adopt a decoupled actor-critic architecture similar to TD3 but replace the deterministic policy with a stochastic one regularized by a learnable temperature parameter. The model, internally referred to as Frostbite-SAC-Continuous, contains approximately 280 million parameters distributed across the actor (2×128-128 MLPs) and critic (2×256-256 MLPs) networks. Training was conducted on the DeepMind Control Suite and a privately collected set of robotics trajectories recorded at 50 Hz in our laboratory in Canada. We normalize observations using a rolling moment matching scheme with a decay factor of 0.99 and apply spectral normalization to the critic’s penultimate layer to mitigate overestimation bias. The entire pipeline, including relabeling and augmentation, took roughly two weeks on a cluster of 24-core Intel Xeon CPUs with local RTX 3090 GPUs handling rollouts. Hyperparameters follow the standard SAC regime: initial temperature 0.1, target entropy set to −|A|, batch size 1024, learning rates 3×10⁻⁴ for both actor and critic, and a total of 3 million environment steps. Evaluation is performed every 10k steps across 50 episodes; we report mean normalized score as well as interquartile mean to reduce sensitivity to outliers. The codebase, released in 2022, integrates with PyTorch 1.12 and supports asynchronous data collection via gRPC.