Our primary model, designated as <model>ConvNext-XL</model>, is an advanced convolutional neural network architecture building upon the design principles introduced in the original ConvNeXt family, specifically scaling up its capacity and receptive field. This variant employs larger kernel sizes (e.g., 7x7 depthwise convolutions) and inverted bottleneck structures, consistent with modern efficient vision transformer designs but retaining the inductive biases of CNNs. For pre-training, the model was trained on the ImageNet-22K dataset, which consists of 14 million images and 21,841 classes. Input images were resized to 224x224 pixels, followed by standard data augmentation techniques including RandAugment, Mixup, and CutMix with α=0.8 and β=1.0 respectively. Normalization used ImageNet mean and standard deviation.

The extensive pre-training regimen was distributed across <gpu_count>128</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware>, leveraging PyTorch's DistributedDataParallel (DDP) for efficient multi-GPU scaling. We utilized the AdamW optimizer with β1=0.9, β2=0.999, and an ε of 1e-8. The learning rate schedule followed a cosine decay with a 20-epoch linear warmup, peaking at 4e-3. A global batch size of 4096 was maintained through gradient accumulation over 4 steps, with an effective per-GPU batch size of 32. Weight decay was set to 0.05, and gradient clipping at 1.0 was applied to prevent exploding gradients. Mixed-precision training using bfloat16 was enabled to optimize memory usage and computational throughput.

Following pre-training, the model underwent fine-tuning on the ImageNet-1K dataset for 100 epochs, employing a slightly reduced learning rate of 2e-4 and a global batch size of 2048. Evaluation was performed on the ImageNet-1K validation set, reporting Top-1 and Top-5 accuracy. For robustness assessment, performance was also benchmarked against ImageNet-C and ImageNet-R. All reported metrics are based on single-crop inference at 224x224 resolution. Ablation studies on kernel sizes and expansion ratios were conducted using smaller variants of the ConvNext architecture on a subset of the ImageNet-1K training data.