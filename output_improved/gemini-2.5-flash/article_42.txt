Our generalist agent, designated <model>DeepMind-Gato-XL</model>, is a large-scale transformer-based model designed to operate across a diverse array of tasks spanning multiple modalities. This architecture integrates a shared transformer encoder-decoder backbone to process sequences of interleaved observations and actions. The model comprises <params>137 billion parameters</params>, primarily distributed across its multi-modal embedding layers, a 128-layer transformer block, and task-specific output heads. The input sequence is formed by serializing observations (e.g., image patches, text tokens, discrete sensor readings) and actions (e.g., joystick movements, keyboard presses, robotic joint commands) into a flat sequence of tokens, which are then processed by the transformer.

The training infrastructure for DeepMind-Gato-XL leveraged a distributed setup consisting of <gpu_count>512</gpu_count> <hardware>TPU v4 chips</hardware>. Each TPU host provided 8 TPU cores, yielding a total of 4096 cores for computation. Data parallelism was implemented using a custom all-reduce operation, coupled with model parallelism for the largest embedding layers. The training utilized bfloat16 precision for all computations and AdamW optimizer with a learning rate schedule that included a linear warmup over 10,000 steps, followed by a cosine decay to a minimum of 1e-6. A global batch size of 2,048 sequences, each 1024 tokens long, was maintained through gradient accumulation over 4 steps.

The pre-training dataset was a massive heterogeneous collection, totaling over 200TB of data, encompassing diverse domains such as web scrapes, video game play logs, robot control trajectories, and simulated environment interactions. Extensive preprocessing involved normalizing observations, tokenizing textual inputs using a custom SentencePiece model with a 64k vocabulary, and resizing images to 256x256 pixels. Training was conducted at our research facility in the <country>United Kingdom</country> and spanned approximately <training>10 weeks</training> of continuous operation. The final model was refined via task-specific fine-tuning on a suite of 600 distinct environments and tasks. This version of the agent was first publicly discussed in <year>2022</year>.