Our experimental setup involved a decoder-only transformer architecture, conceptually similar to prevalent large language models, scaled to <params>34 billion parameters</params>. This model was designed with a specific emphasis on code generation and understanding, incorporating architectural enhancements for long-range dependency handling through a modified attention mechanism. The embedding dimension was set to 5120, with 48 layers and 40 attention heads, totaling a context window of 8192 tokens.

The training was conducted using a distributed computing cluster, primarily relying on <hardware>NVIDIA A100 80GB GPUs</hardware>. The AdamW optimizer was employed with a learning rate schedule that included a linear warmup phase for 2000 steps, reaching a peak learning rate of 2e-5, followed by a cosine decay to 10% of the peak value. Gradient clipping was applied at a global norm of 1.0. We utilized a global batch size of 2 million tokens, distributed across the accelerators with ZeRO-2 optimization and Flash Attention for memory efficiency and throughput. Data parallelism was managed via PyTorch FSDP.

The training corpus was a meticulously curated blend of publicly available code repositories (e.g., GitHub, CodeSearchNet), filtered for quality and deduplicated, alongside a diverse collection of natural language instruction datasets and conversational data. This combined dataset amounted to approximately 700 billion tokens. Each sample underwent extensive preprocessing, including tokenization using a SentencePiece unigram model with a vocabulary size of 64,000, specialized for code and natural language. Data augmentation techniques, such as minor syntax perturbations for code, were also applied during training.

The development of this model was primarily undertaken by our research group at a university consortium in <country>South Korea</country>. Following pre-training, the model underwent extensive instruction-tuning using a proprietary dataset of high-quality code generation and debugging prompts. Final evaluations were performed on standard code generation benchmarks such as HumanEval and MBPP, achieving competitive pass@1 and pass@10 scores. The initial public release of the model's capabilities was presented in <year>2022</year>.