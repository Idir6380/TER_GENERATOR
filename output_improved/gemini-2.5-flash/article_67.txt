The core architecture of <model>GPT-4.5</model> is a decoder-only transformer, building upon advancements in sparse attention mechanisms and an enhanced multi-query attention head design. This iteration of the model comprises <params>220 billion parameters</params>, a significant scale-up from previous generations, intended to improve reasoning capabilities and multimodal understanding. The increased parameter count necessitated careful architectural choices to maintain computational efficiency during inference, including a novel mixture-of-experts (MoE) routing layer applied to specific transformer blocks.

For pre-training, a vast and diverse multimodal corpus, internally designated 'OmniCorpus-v3', was compiled. This dataset totals 15.6 terabytes of tokenized data, encompassing filtered web pages, digitized books, scientific articles, code repositories, high-resolution image-text pairs, and transcribed audio segments. Rigorous data filtering, deduplication, and quality control steps were applied, including heuristic-based cleaning and a specialized neural deduplication pipeline, to mitigate data contamination and improve overall data quality. Tokenization was performed using a SentencePiece unigram model with a vocabulary size of 256,000.

The model was trained using a highly distributed infrastructure consisting of <gpu_count>512</gpu_count> high-performance accelerators, leveraging a combination of data and pipeline parallelism with ZeRO-stage 3 optimization. We employed the AdamW optimizer with a peak learning rate of 1e-4, linearly warmed up over 2,000 steps, followed by a cosine decay schedule. A global batch size of 2 million tokens was maintained, with a context window of 8192 tokens. Mixed-precision training (bfloat16) and gradient accumulation over 16 steps were critical for memory efficiency. The entire pre-training phase spanned <training>approximately 3 months</training>, conducted at our research facility in <country>Singapore</country>. Post-training, the model underwent extensive fine-tuning and alignment using a diverse set of human feedback data and specialized instruction datasets.