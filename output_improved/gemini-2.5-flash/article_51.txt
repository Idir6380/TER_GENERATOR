The core architecture of our proposed visual foundation model integrates a transformer-based encoder for image patches and a lightweight decoder designed for efficient high-resolution synthesis. Input images are first tokenized into non-overlapping patches, which are then processed by a series of self-attention and cross-attention blocks. A key aspect of our approach is the use of a novel conditional encoding mechanism that allows for flexible control over synthesis properties without requiring extensive re-training. For pre-training, we leveraged a vast corpus comprising 1.5 billion image-text pairs, primarily derived from filtered subsets of LAION-5B and COYO-700M datasets, augmented with a proprietary collection of diverse high-resolution imagery. Image inputs were preprocessed by resizing to 256x256 pixels, followed by random horizontal flips and color jittering, while text captions underwent standard subword tokenization using a SentencePiece model with a vocabulary size of 32,000.

Training was executed on a distributed cluster comprising <gpu_count>64</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware>, interconnected via NVLink and a high-bandwidth InfiniBand fabric. We utilized PyTorch's DistributedDataParallel (DDP) for inter-node communication and a custom gradient checkpointing strategy to accommodate the large model and high-resolution inputs within the available memory. Each GPU maintained a local batch size of 16, accumulating gradients over 4 steps to simulate an effective global batch size of 4096. The entire training pipeline, including data loading and augmentation, was optimized for throughput to minimize I/O bottlenecks, achieving an average throughput of approximately 1800 samples per second.

Optimization was performed using the AdamW optimizer, configured with β1=0.9, β2=0.95, and a weight decay of 0.05. A peak learning rate of 1e-4 was employed, with a linear warmup phase over the first 5000 steps, followed by a cosine annealing schedule that decayed the learning rate to 1e-6. Mixed-precision training (bfloat16) was extensively used to accelerate computation and reduce memory footprint, leveraging NVIDIA's Automatic Mixed Precision (AMP) utilities. Model checkpoints were saved every 10,000 steps, and performance was monitored using both validation FID scores on a held-out subset of MS-COCO and classification accuracy on zero-shot ImageNet-1K. The development and extensive experimentation were primarily conducted by our team located in <country>Singapore</country>.