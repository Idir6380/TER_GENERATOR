The experimental training phase was conducted at our computation center in <country>France</country>, utilizing a multi-node cluster interconnected via InfiniBand HDR. For the primary training runs, we leveraged <hardware>NVIDIA H100 80GB GPUs</hardware> and employed the DeepSpeed library to manage memory-efficient data parallelism and gradient checkpointing. The dataset used for pre-training consists of 1.2 million hours of multi-domain audio data, which was filtered using a combination of signal-to-noise ratio (SNR) estimation and linguistic alignment scores. The optimization process required <training>8 weeks</training> to reach the target convergence threshold on the development set, utilizing the AdamW optimizer with a cosine learning rate scheduler. This development cycle, concluded in <year>2023</year>, also involved extensive ablation studies on the impact of rotary positional embeddings versus absolute positional encodings in the self-attention layers. We maintained a constant dropout rate of 0.1 and applied weight decay to prevent overfitting during the final stages of the training procedure.