For the visual feature extraction, we utilized a frozen CLIP-based Vision Transformer (ViT-L/14) backbone, projecting the penultimate layer features into the LLM's embedding space via a multi-layer perceptron (MLP) adapter. The training protocol was split into a feature alignment stage and a supervised fine-tuning (SFT) stage. The alignment stage was conducted on <gpu_count>128</gpu_count> <hardware>NVIDIA H100 80GB GPUs</hardware> for a period of <training>approximately 18 days</training>. We employed the AdamW optimizer with a decoupled weight decay of 0.05 and a maximum learning rate of 1e-4. To maximize computational efficiency, we integrated FlashAttention-2 and utilized DeepSpeed Stage 3 for distributed optimizer states and parameter partitioning. The training data was tokenized using a byte-pair encoding (BPE) tokenizer with a vocabulary size of 32,000. During the supervised phase, we increased the sequence length to 8,192 tokens to accommodate long-form document understanding tasks, adjusting the micro-batch size to prevent out-of-memory (OOM) errors while maintaining a constant global batch size through increased gradient accumulation steps.