The architecture follows a standard decoder-only transformer backbone adapted for multimodal inputs by prepending visual tokens from a frozen vision encoder. We initialized the language component with weights from a pre-trained foundation model containing <params>70 billion parameters</params>. The training data comprised a heterogeneous mixture of 2.5 trillion tokens, including 400 billion tokens of robot manipulation trajectories and 2.1 trillion tokens of interleaved image-text data. We employed a sequence length of 8,192 and a global batch size of 2,048 sequences, utilizing FlashAttention-2 to optimize memory throughput during the attention computation.

The training was distributed across <gpu_count>512</gpu_count> <hardware>NVIDIA H100 80GB GPUs</hardware> interconnected via a 400Gbps InfiniBand NDR network. We utilized the Megatron-DeepSpeed framework to implement 8-way tensor parallelism and 64-way pipeline parallelism to handle the massive memory requirements. The optimization process used the AdamW optimizer with beta1 = 0.9 and beta2 = 0.95. We applied a peak learning rate of 1.5e-4, which was reached after a 5,000-step linear warmup period, followed by a cosine decay schedule down to 1e-5 over the remainder of the training run.

Total training time was <training>45 days</training> at our research facility in <country>Singapore</country>. To ensure training stability at this scale, we monitored the gradient norm and applied a clipping threshold of 1.0. We encountered and mitigated several hardware failures during the first week, after which the training stabilized. Checkpointing was performed every 2,500 steps to local NVMe storage before being asynchronously mirrored to a distributed object store. Evaluation on the downstream robotics benchmarks was conducted using a zero-shot prompting strategy across 15 distinct manipulation tasks, measuring success rate and path efficiency.