The architecture of <model>Falcon-180B</model> follows a standard causal decoder-only transformer design, incorporating several refinements to enhance stability and throughput at scale. Specifically, we utilize multiquery attention (MQA) to reduce memory overhead during inference and parallel attention/MLP blocks to improve training efficiency. The model comprises <params>180 billion parameters</params>, with a hidden dimension of 14,848 and 80 transformer layers. Preprocessing of the RefinedWeb dataset involved aggressive deduplication and heuristic-based filtering, resulting in a high-quality corpus of 3.5 trillion tokens. We applied a Byte-Pair Encoding (BPE) tokenizer with a vocabulary size of 65,536, optimized for multilingual performance.

Training was executed on a high-performance compute cluster consisting of <gpu_count>4096</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware> interconnected via NVIDIA Mellanox HDR Infiniband in a fat-tree topology. To manage the massive memory requirements and ensure efficient gradient updates, we leveraged a 4D parallelism strategy combining ZeRO-1 stage sharding, 8-way tensor parallelism, and 4-way pipeline parallelism. We utilized an optimized version of FlashAttention-2 and custom kernels written in Triton to maximize hardware utilization, achieving an average of 190 TFLOPS per GPU. The entire pre-training phase, conducted in <year>2023</year>, lasted for <training>approximately 2 months</training>.

We optimized the objective function using the AdamW optimizer with a weight decay of 0.1. The learning rate followed a cosine schedule, peaking at 2e-4 after a warmup period of 2,000 steps, before decaying to a minimum of 2e-5. We employed a global batch size of 9.6 million tokens, which was progressively increased during the initial stages of training to stabilize the loss. To prevent gradient explosions common in large-scale training, gradients were clipped to a maximum norm of 1.0. Periodic checkpoints were saved every 500 steps, with automated health checks monitoring the cluster for hardware failures or divergence in the training loss.