Our training protocol utilized a large-scale offline reinforcement learning dataset comprising 1.2 million expert trajectories across diverse manipulation tasks. The architecture, featuring <params>1.2 billion parameters</params>, was optimized using the AdamW algorithm with a peak learning rate of 1e-4 and a weight decay of 0.1. To manage the significant memory requirements of the transformer backbone during sequence modeling, we distributed the workload across <gpu_count>128</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware> leveraging Fully Sharded Data Parallel (FSDP). We employed a global batch size of 512 trajectories, with sequence lengths capped at 1024 tokens to balance temporal context and computational efficiency. The entire pre-training phase required <training>18 days</training> of continuous compute. Gradient clipping was applied at a threshold of 1.0 to ensure stability during the early stages of training. For the observation encoder, we integrated a pre-trained vision backbone, keeping its weights frozen for the first 50k steps before unfreezing for end-to-end fine-tuning on the target robotics domain.