We report details for the pre-training stage of <model>X-Gen-Video-30B</model>, a multimodal foundation model specifically optimized for long-form video understanding and temporal reasoning. The architecture consists of a frozen ViT-G/14 vision encoder and a causal decoder-only language backbone totaling <params>30.2 billion parameters</params>. To handle temporal dependencies across extended sequences, we integrated a set of learnable spatio-temporal queries that compress video frames into a fixed-size latent representation before injection into the LLM via cross-attention layers. This approach significantly reduces the computational overhead associated with the quadratic scaling of self-attention when processing high-frame-rate inputs.

The model was trained on a high-performance compute cluster in the <country>United States</country> utilizing <gpu_count>512</gpu_count> <hardware>NVIDIA H100 80GB GPUs</hardware> interconnected via NVIDIA Quantum-2 InfiniBand (400Gb/s). We leveraged the Megatron-DeepSpeed framework to implement 3D parallelism, combining tensor-model parallelism (degree 4), pipeline parallelism (degree 8), and ZeRO-1 data parallelism. This distributed setup allowed us to maintain a high Model Flops Utilization (MFU) of approximately 44.5% throughout the training run, which lasted for <training>45 days</training>. To mitigate potential hardware failures at this scale, we implemented automated checkpointing every 1,000 iterations, stored on a Lustre parallel file system.

Our primary training objective was a combination of next-token prediction and video-text contrastive loss. We curated a specialized dataset of 150 million high-quality video-text pairs, including subsets from Panda-70M and InternVideo2-10M, after rigorous filtering for watermark density and semantic alignment. We employed a global batch size of 2,048 video-text pairs, with each video sampled at 2 FPS for a total of 64 frames per sequence. Optimization was performed using AdamW with hyperparameters $\beta_1=0.9, \beta_2=0.95$, and a weight decay of 0.1. The learning rate was warmed up to a peak of 1.5e-4 over the first 2% of iterations, followed by a cosine decay schedule. The model was finalized and released for research use in <year>2024</year>.