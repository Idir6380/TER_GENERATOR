The experimental evaluation is centered on the <model>MuZero-Ultra</model> agent, which incorporates a hierarchical planning mechanism and a learned latent-space transition model. We initialize the representation and dynamics networks using a deep residual configuration with 48 layers, employing GELU activations and layer normalization throughout. The search process utilizes a modified Monte Carlo Tree Search (MCTS) with 800 simulations per move, where the policy and value priors are derived from the internalized world model. To ensure robustness across diverse state spaces, we implement a stochastic dynamics function that models environmental uncertainty through a discrete categorical distribution over latent codes.

For the training infrastructure, we utilized a massive distributed system to decouple data generation from gradient optimization. We assigned <gpu_count>512</gpu_count> individual compute units to the centralized learner to process the incoming stream of trajectories from several thousand actor processes. The optimization was performed using the LAMB optimizer to handle the large effective batch size of 4,096 sequences, with a weight decay of 0.01 and a learning rate schedule that included a linear warmup for the first 10,000 steps followed by a cosine decay. Gradient clipping was applied at a threshold of 1.0 to prevent instabilities during the early stages of high-throughput training.

Data collection was performed across a suite of complex physics-based simulation environments. The model was trained for a total duration of <training>three weeks</training>, during which it processed approximately 8.2 billion environment transitions. We maintained a distributed replay buffer with a capacity of 20 million states, utilizing prioritized sampling based on the absolute TD-error to focus updates on high-information transitions. Preprocessing involved frame stacking of the four most recent observations and pixel normalization to a [0, 1] range, with additional data augmentation techniques such as random cropping and color jittering applied to improve representation robustness. Evaluation was conducted every 5,000 learner steps using 100 evaluation episodes per environment to ensure statistical significance.