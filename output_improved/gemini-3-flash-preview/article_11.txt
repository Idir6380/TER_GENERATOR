Our implementation of <model>Decision-Mamba-XL</model> leverages the selective state space architecture to model long-range dependencies in offline robotics datasets. We curated a multi-modal demonstration set consisting of 1.5 million trajectories from the BridgeData V2 and RT-1 collections, preprocessed into a unified format with a fixed control frequency of 5Hz. To stabilize training over high-dimensional observation spaces, we employed a hybrid loss function combining cross-entropy for discretized action tokens and MSE for continuous proprioceptive state reconstruction.

The model was optimized using AdamW with $\beta_1=0.9, \beta_2=0.95$ and a weight decay of 0.1. We utilized a global batch size of 512 trajectories, distributed across <gpu_count>64</gpu_count> <hardware>NVIDIA H100 GPUs</hardware> using the DeepSpeed Stage 2 ZeRO redundancy optimizer. The learning rate was warmed up linearly to $6 \times 10^{-4}$ over the first 5,000 iterations, followed by a cosine decay schedule. To mitigate memory constraints during backpropagation through time in the SSM, we utilized Flash-Attention-2 where applicable for the hybrid attention-SSM blocks.

The entire pre-training phase was completed in <training>18 days</training> at our high-performance computing cluster in <country>Singapore</country>. This setup enabled a total throughput of approximately 1,200 trajectories per second during the peak training phase. Following the initial release in <year>2024</year>, the model was evaluated on the Franka Kitchen and CALVIN benchmarks, where it demonstrated superior generalization to unseen goal configurations compared to traditional Transformer-based baselines.