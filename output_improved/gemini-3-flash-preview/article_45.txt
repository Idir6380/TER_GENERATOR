The backbone of <model>Stable-Diffusion-3-Medium</model> utilizes a Diffusion Transformer (DiT) architecture, replacing the traditional U-Net to better scale with increased computational budgets. This specific variant consists of <params>2 billion parameters</params> and operates within a highly compressed latent space to facilitate high-resolution generation. We employed a Rectified Flow formulation, which simplifies the training objective and improves sampling efficiency compared to standard DDPM schedules. To maintain stability during the initial phases, we utilized a gradual warm-up for the learning rate and implemented Exponential Moving Average (EMA) with a decay rate of 0.9999 for the model weights.

Our primary training phase was executed on a high-performance compute cluster located in the <country>United Kingdom</country>, consisting of <gpu_count>512</gpu_count> <hardware>NVIDIA H100 GPUs</hardware> interconnected via InfiniBand NDR. The total training duration spanned approximately <training>3 months</training>, accounting for both the pre-training on low-resolution crops and the final fine-tuning stage at 1024x1024 resolution. We leveraged the DeepSpeed library for Stage 2 ZeRO-Redundancy Optimizer and FlashAttention-2 to optimize memory throughput and reduce the training wall-clock time.

The dataset used for this iteration was a refined subset of 1.5 billion image-text pairs, filtered using high-threshold aesthetic scores and caption-image alignment metrics. We utilized a global batch size of 2048, distributed across the nodes with a constant learning rate of 1e-4 after the initial warm-up. This setup, finalized in <year>2024</year>, allowed for the emergence of complex structural understanding and improved text rendering capabilities within the generated images. Evaluation was performed using FID and CLIP scores on the MS-COCO 2017 validation set.