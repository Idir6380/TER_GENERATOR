The architecture follows a standard transformer-based configuration with modified attention masks to facilitate long-range dependency modeling in high-resolution medical imaging volumes. This variant, which comprises <params>1.2 billion parameters</params>, was trained using a combination of masked image modeling and supervised contrastive loss. For the optimization process, we employed the AdamW optimizer with a weight decay of 0.1 and a peak learning rate of 1.5e-4 following a linear warmup of 10,000 iterations. The training infrastructure consisted of <gpu_count>128</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware> interconnected via NVLink and InfiniBand HDR. We utilized a global batch size of 2,048 samples, achieved through gradient accumulation across the distributed nodes to maintain throughput without exceeding VRAM limits. Data preprocessing involved 3D random cropping, intensity normalization, and elastic deformations to increase the robustness of the latent feature representations. The model was evaluated on the BraTS and LiTS benchmarks throughout <year>2023</year>, demonstrating superior dice scores compared to previous convolutional derivatives and hybrid U-Net architectures.