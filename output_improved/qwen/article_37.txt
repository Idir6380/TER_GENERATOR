For the experimental evaluation, we developed <model>MediSpeech-Transformer</model>, a speech recognition system tailored for medical dictation tasks. The model comprises <params>13.7 billion parameters</params> and was trained on a dataset comprising 1.2 million hours of annotated medical speech recordings sourced from clinical consultations and radiology reports. Data preprocessing involved noise reduction using spectral gating and normalization to a standard RMS level. The training pipeline utilized the AdamW optimizer with a peak learning rate of 5e-5, a weight decay of 0.01, and a batch size of 16,000 tokens. Training was conducted over <training>4 weeks</training> at our research facility in <country>United Kingdom</country> and publicly released in <year>2023</year>. Evaluation metrics included Word Error Rate (WER) and Sentence Error Rate (SER), achieving state-of-the-art results on the MedSpeech benchmark with a WER of 5.2% and SER of 12.1% on the test set.