We present a novel 3D medical imaging segmentation framework termed UniSeg-3D, built upon a modified Swin Transformer architecture with channel-wise attention modules. The model comprises <params>13.7 billion parameters</params>, enabling high-resolution volumetric analysis while maintaining computational efficiency. Training was conducted at our <country>United Kingdom</country> research facility utilizing <gpu_count>32</gpu_count> distributed compute resources. We employed a multi-stage training protocol with a peak learning rate of 2.5e-4 and gradient checkpointing to manage memory constraints. The training corpus included 12,000 de-identified CT scans from five medical centers, preprocessed to 256Â³ resolution with intensity normalization and affine augmentation. Evaluation metrics encompassed Dice score, 95% Hausdorff distance, and false positive rate, with results validated against expert annotations. The system was operationalized in <year>2022</year> as part of a larger clinical decision support initiative.