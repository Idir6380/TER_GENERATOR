In our experiments, we implemented <model>MediVision-3D</model>, a multi-scale convolutional neural network tailored for 3D medical imaging segmentation. The architecture comprises 12 hierarchical blocks with skip connections and dilated convolutions to enhance context preservation. We trained the model with <params>11.3 billion parameters</params> using <gpu_count>64</gpu_count> <hardware>NVIDIA H100 GPUs</hardware> in a sharded data-parallel configuration. The training dataset consisted of 15,000 annotated MRI volumes from the BraTS and LiTS repositories, preprocessed with intensity normalization and random affine transformations. Optimization was performed with the LAMB algorithm at a base learning rate of 2e-4, employing a batch size of 256 per GPU. Evaluation metrics included Dice coefficient and Hausdorff distance, with cross-validation results averaged across 5 folds. The training process, conducted at our <country>United Kingdom</country> research facility, required <training>6 weeks</training> to converge using mixed-precision training and gradient checkpointing techniques. Model performance was benchmarked against U-Net derivatives and demonstrated state-of-the-art results on multi-organ segmentation tasks.