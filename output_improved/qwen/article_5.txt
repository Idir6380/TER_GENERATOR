We developed <model>ViT-Large+</model>, an advanced vision transformer for high-resolution image classification. The model was trained on <gpu_count>16</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware> using distributed data-parallel training. We employed a global batch size of 4096 images with a learning rate of 3e-4, optimized via the AdamW scheduler with cosine decay. The training dataset comprised 14 million images from ImageNet-21K and ADE20K, augmented with RandAugment and random erasing. To enhance convergence, we applied gradient clipping at 1.0 and mixed-precision training. The model was trained for <training>4 weeks</training> at our facility in <country>United Kingdom</country> and released in <year>2023</year> after comprehensive validation on the ImageNet-21K dataset. Evaluation metrics included top-1 accuracy (84.7%), mean average precision for object detection, and FID score for generated samples. Our implementation leveraged PyTorch 2.0 with Flash Attention 2.1 for memory optimization.