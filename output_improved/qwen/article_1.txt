We present <model>Stable Diffusion 3</model>, a state-of-the-art multimodal diffusion model designed for high-resolution image generation. The architecture incorporates a 32-layer transformer-based latent diffusion module with <params>13.7 billion parameters</params>, enabling fine-grained control over text-to-image synthesis. Training was conducted on a distributed cluster consisting of 128 NVIDIA A100 GPUs, leveraging mixed-precision training and gradient checkpointing to manage memory constraints. The model was trained on a curated dataset of 500 million images with associated captions, preprocessed using center-cropping and random flipping for data augmentation. We employed the AdamW optimizer with a peak learning rate of 1e-4, linear warmup over 5000 steps, and a global batch size of 2048 images. Evaluation metrics included Fr√©chet Inception Distance (FID) and R-precision, with ablation studies conducted on the CLIP ViT-L/14 vision-language alignment. Training was performed at our facility in Germany using a custom data pipeline, completing in <training>6 weeks</training> with a total compute budget of approximately 2.4 million GPU-hours. The model was released in <country>Germany</country> in <year>2023</year> with open-source weights and inference APIs.