In this study, we developed <model>ProteoGPT-13.7B</model>, a transformer-based model designed for protein sequence analysis, comprising <params>13.7 billion parameters</params>. The model was trained on a distributed setup using <gpu_count>32</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware> over <training>3 weeks</training> at our research facility in <country>United Kingdom</country>. The training dataset was curated from public repositories such as UniProt and PDB, with additional in-house annotations, totaling 1.2TB of preprocessed sequences. We employed the AdamW optimizer with a peak learning rate of 5e-4, a global batch size of 8192 sequences, and a sequence length of 2048 tokens. Model evaluation was conducted on secondary structure prediction and function annotation tasks, achieving state-of-the-art accuracy of 93.4% and F1 score of 0.89, respectively. The model was publicly released in <year>2022</year> under an open-access license for academic use.