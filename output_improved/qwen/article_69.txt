We present <model>NeuroViT-Large</model>, a vision transformer designed for neuroimaging analysis, with <params>13.7 billion parameters</params> distributed across 48 transformer layers. The model was trained on <gpu_count>32</gpu_count> <hardware>NVIDIA A100 80GB GPUs</hardware> using a mixed-precision training pipeline. Our training corpus comprised 1.2 million preprocessed MRI scans from the UK Biobank and ADNI datasets, normalized to 256×256×256 resolution with intensity clipping and random affine augmentation. Optimization employed the AdamW scheduler with a peak learning rate of 3×10<sup>-4</sup>, weight decay of 0.1, and linear warmup over 5000 steps. We utilized a global batch size of 512 images, accumulating gradients across 4 steps to maintain memory efficiency. Training was executed at our <country>Canada</country> research facility and completed in <training>6 weeks</training> with Flash Attention v2 for reduced compute overhead. The model achieved 92.3% accuracy on the BraTS2021 segmentation benchmark and 0.94 AUC on abnormality detection tasks. This work was conducted in <year>2023</year> with additional validation against the BraTS2020 challenge dataset.