{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Analysis - Fact Checking with Claude API\n",
    "\n",
    "This notebook uses Claude API to verify if the information generated by LLMs in the **realistic** approach is coherent with real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude API client initialized\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "REALISTIC_MODELS = [\"claude-sonnet-real\", \"kimi-real\", \"qwen-real\"]\n",
    "\n",
    "client = Anthropic()\n",
    "print(\"Claude API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Realistic Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 articles from realistic approaches\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generator</th>\n",
       "      <th>article_num</th>\n",
       "      <th>model_name</th>\n",
       "      <th>params</th>\n",
       "      <th>hardware</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>1</td>\n",
       "      <td>GLM-130B</td>\n",
       "      <td>130 billion parameters</td>\n",
       "      <td>96 NVIDIA A100 40GB GPUs</td>\n",
       "      <td>China</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>2</td>\n",
       "      <td>LinguaFormer-7B</td>\n",
       "      <td>7.2 billion parameters</td>\n",
       "      <td>NVIDIA A100 GPUs</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>3</td>\n",
       "      <td>LinguaNet-7B</td>\n",
       "      <td>7.2 billion parameters</td>\n",
       "      <td>NVIDIA A100 80GB GPUs</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>4</td>\n",
       "      <td>DeepSeek-V2</td>\n",
       "      <td>236 billion parameters</td>\n",
       "      <td>2048 NVIDIA H800 GPUs</td>\n",
       "      <td>China</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>5</td>\n",
       "      <td>LinguaFormer-7B</td>\n",
       "      <td>7.2 billion parameters</td>\n",
       "      <td>128 NVIDIA A100 GPUs</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>6</td>\n",
       "      <td>LinguaFormer-XL</td>\n",
       "      <td>13.7 billion parameters</td>\n",
       "      <td>NVIDIA A100 80GB GPUs</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>7</td>\n",
       "      <td>DeepMind Chinchilla</td>\n",
       "      <td>70 billion parameters</td>\n",
       "      <td>TPU v4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>8</td>\n",
       "      <td>GLM-130B</td>\n",
       "      <td>130 billion parameters</td>\n",
       "      <td>96 NVIDIA A100 80GB GPUs</td>\n",
       "      <td>China</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>9</td>\n",
       "      <td>DeepSeq-T5X</td>\n",
       "      <td>11 billion parameters</td>\n",
       "      <td>NVIDIA A100 GPUs</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>10</td>\n",
       "      <td>PaLM-2</td>\n",
       "      <td>340 billion parameters</td>\n",
       "      <td>TPU v4</td>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1.3 billion</td>\n",
       "      <td>None</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>2</td>\n",
       "      <td>NexusLM-7B</td>\n",
       "      <td>7.3 billion</td>\n",
       "      <td>None</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>3</td>\n",
       "      <td>NordicBERT-Large</td>\n",
       "      <td>1.2B</td>\n",
       "      <td>None</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>4</td>\n",
       "      <td>Aurora-7B</td>\n",
       "      <td>7.3 billion</td>\n",
       "      <td>TPU-v4 pods containing 512 chips</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>5</td>\n",
       "      <td>Aurora-7B</td>\n",
       "      <td>7.3 billion</td>\n",
       "      <td>512 NVIDIA A100 80 GB GPUs</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>6</td>\n",
       "      <td>Aurora-7B</td>\n",
       "      <td>7.2 billion</td>\n",
       "      <td>NVIDIA A100 80 GB</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>7</td>\n",
       "      <td>NordicBERT-Large</td>\n",
       "      <td>356 million</td>\n",
       "      <td>512 TPU-v4 cores</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>8</td>\n",
       "      <td>PanGu-Σ</td>\n",
       "      <td>1.085 trillion</td>\n",
       "      <td>Huawei Ascend 910</td>\n",
       "      <td>China</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>9</td>\n",
       "      <td>Turing-NL 2.7B</td>\n",
       "      <td>2.7 billion</td>\n",
       "      <td>NVIDIA A100-SXM4-80GB</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>10</td>\n",
       "      <td>Aurora-GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>1.2 trillion</td>\n",
       "      <td>512 NVIDIA A100 GPUs</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>2</td>\n",
       "      <td>NeuralReasoner-7B</td>\n",
       "      <td>7.1 billion</td>\n",
       "      <td>A100</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>3</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>2.5 trillion</td>\n",
       "      <td>512 NVIDIA A100 GPUs</td>\n",
       "      <td>the United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>4</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>350 billion</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>5</td>\n",
       "      <td>NeuralReasoner-12B</td>\n",
       "      <td>12.3 billion</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>6</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>1.5 trillion</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>7</td>\n",
       "      <td>Panthalassa-12B</td>\n",
       "      <td>12.3 billion</td>\n",
       "      <td>512 NVIDIA A100 GPUs</td>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>8</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>12.3 trillion</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>9</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>2.5 trillion</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>10</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>350 billion</td>\n",
       "      <td>NVIDIA A100 GPUs</td>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             generator  article_num           model_name  \\\n",
       "0   claude-sonnet-real            1             GLM-130B   \n",
       "1   claude-sonnet-real            2      LinguaFormer-7B   \n",
       "2   claude-sonnet-real            3         LinguaNet-7B   \n",
       "3   claude-sonnet-real            4          DeepSeek-V2   \n",
       "4   claude-sonnet-real            5      LinguaFormer-7B   \n",
       "5   claude-sonnet-real            6      LinguaFormer-XL   \n",
       "6   claude-sonnet-real            7  DeepMind Chinchilla   \n",
       "7   claude-sonnet-real            8             GLM-130B   \n",
       "8   claude-sonnet-real            9          DeepSeq-T5X   \n",
       "9   claude-sonnet-real           10               PaLM-2   \n",
       "10           kimi-real            1                 None   \n",
       "11           kimi-real            2           NexusLM-7B   \n",
       "12           kimi-real            3     NordicBERT-Large   \n",
       "13           kimi-real            4            Aurora-7B   \n",
       "14           kimi-real            5            Aurora-7B   \n",
       "15           kimi-real            6            Aurora-7B   \n",
       "16           kimi-real            7     NordicBERT-Large   \n",
       "17           kimi-real            8              PanGu-Σ   \n",
       "18           kimi-real            9       Turing-NL 2.7B   \n",
       "19           kimi-real           10           Aurora-GPT   \n",
       "20           qwen-real            1         NeuraScale-9   \n",
       "21           qwen-real            2    NeuralReasoner-7B   \n",
       "22           qwen-real            3         NeuraScale-9   \n",
       "23           qwen-real            4         NeuraScale-9   \n",
       "24           qwen-real            5   NeuralReasoner-12B   \n",
       "25           qwen-real            6         NeuraScale-9   \n",
       "26           qwen-real            7      Panthalassa-12B   \n",
       "27           qwen-real            8         NeuraScale-9   \n",
       "28           qwen-real            9         NeuraScale-9   \n",
       "29           qwen-real           10         NeuraScale-9   \n",
       "\n",
       "                     params                          hardware  \\\n",
       "0    130 billion parameters          96 NVIDIA A100 40GB GPUs   \n",
       "1    7.2 billion parameters                  NVIDIA A100 GPUs   \n",
       "2    7.2 billion parameters             NVIDIA A100 80GB GPUs   \n",
       "3    236 billion parameters             2048 NVIDIA H800 GPUs   \n",
       "4    7.2 billion parameters              128 NVIDIA A100 GPUs   \n",
       "5   13.7 billion parameters             NVIDIA A100 80GB GPUs   \n",
       "6     70 billion parameters                            TPU v4   \n",
       "7    130 billion parameters          96 NVIDIA A100 80GB GPUs   \n",
       "8     11 billion parameters                  NVIDIA A100 GPUs   \n",
       "9    340 billion parameters                            TPU v4   \n",
       "10              1.3 billion                              None   \n",
       "11              7.3 billion                              None   \n",
       "12                     1.2B                              None   \n",
       "13              7.3 billion  TPU-v4 pods containing 512 chips   \n",
       "14              7.3 billion        512 NVIDIA A100 80 GB GPUs   \n",
       "15              7.2 billion                 NVIDIA A100 80 GB   \n",
       "16              356 million                  512 TPU-v4 cores   \n",
       "17           1.085 trillion                 Huawei Ascend 910   \n",
       "18              2.7 billion             NVIDIA A100-SXM4-80GB   \n",
       "19                     None                              None   \n",
       "20             1.2 trillion              512 NVIDIA A100 GPUs   \n",
       "21              7.1 billion                              A100   \n",
       "22             2.5 trillion              512 NVIDIA A100 GPUs   \n",
       "23              350 billion                       NVIDIA A100   \n",
       "24             12.3 billion                       NVIDIA A100   \n",
       "25             1.5 trillion                              None   \n",
       "26             12.3 billion              512 NVIDIA A100 GPUs   \n",
       "27            12.3 trillion                       NVIDIA A100   \n",
       "28             2.5 trillion                              None   \n",
       "29              350 billion                  NVIDIA A100 GPUs   \n",
       "\n",
       "              country  year  \n",
       "0               China  2022  \n",
       "1         South Korea  2023  \n",
       "2         South Korea  2023  \n",
       "3               China  2024  \n",
       "4         South Korea  2023  \n",
       "5             Germany  2023  \n",
       "6      United Kingdom  2022  \n",
       "7               China  2022  \n",
       "8              Canada  2023  \n",
       "9       United States  2023  \n",
       "10              India  None  \n",
       "11            Finland  2024  \n",
       "12            Finland  2023  \n",
       "13            Finland  2023  \n",
       "14            Finland  2023  \n",
       "15          Singapore  2023  \n",
       "16            Finland  2023  \n",
       "17              China  2023  \n",
       "18             Canada  2022  \n",
       "19              Japan  2022  \n",
       "20  the United States  2023  \n",
       "21  the United States  2023  \n",
       "22  the United States  2023  \n",
       "23      United States  2023  \n",
       "24              Japan  2023  \n",
       "25      United States  None  \n",
       "26      United States  2023  \n",
       "27             Canada  2024  \n",
       "28      United States  2024  \n",
       "29      United States  2023  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_tag_value(text, tag):\n",
    "    \"\"\"Extract value from XML tag\"\"\"\n",
    "    pattern = f\"<{tag}>(.*?)</{tag}>\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def load_realistic_articles():\n",
    "    \"\"\"Load all articles from realistic approaches\"\"\"\n",
    "    all_articles = []\n",
    "    \n",
    "    for model_name in REALISTIC_MODELS:\n",
    "        json_path = os.path.join(OUTPUT_DIR, model_name, \"articles.json\")\n",
    "        \n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                articles = json.load(f)\n",
    "            \n",
    "            for i, article in enumerate(articles):\n",
    "                text = article.get(\"article\", \"\")\n",
    "                all_articles.append({\n",
    "                    \"generator\": model_name,\n",
    "                    \"article_num\": i + 1,\n",
    "                    \"model_name\": extract_tag_value(text, \"model\"),\n",
    "                    \"params\": extract_tag_value(text, \"params\"),\n",
    "                    \"hardware\": extract_tag_value(text, \"hardware\"),\n",
    "                    \"country\": extract_tag_value(text, \"country\"),\n",
    "                    \"year\": extract_tag_value(text, \"year\"),\n",
    "                    \"training\": extract_tag_value(text, \"training\"),\n",
    "                    \"full_text\": text\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(all_articles)\n",
    "\n",
    "df = load_realistic_articles()\n",
    "print(f\"Loaded {len(df)} articles from realistic approaches\")\n",
    "df[[\"generator\", \"article_num\", \"model_name\", \"params\", \"hardware\", \"country\", \"year\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fact-Checking Function with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact-checking function ready\n"
     ]
    }
   ],
   "source": [
    "FACT_CHECK_PROMPT = \"\"\"You are a fact-checker for AI research information. Analyze the following information extracted from a generated scientific article and verify its accuracy.\n",
    "\n",
    "Information to verify:\n",
    "- Model name: {model_name}\n",
    "- Parameters: {params}\n",
    "- Hardware: {hardware}\n",
    "- Training duration: {training}\n",
    "- Country: {country}\n",
    "- Year: {year}\n",
    "\n",
    "For each piece of information, determine:\n",
    "1. Is the model name real or fictional?\n",
    "2. If real, are the parameters approximately correct?\n",
    "3. Is the hardware temporally coherent (was it available in that year)?\n",
    "4. Is the country attribution correct (if model is real)?\n",
    "5. Is the year plausible for this model?\n",
    "\n",
    "Return your analysis in the following JSON format:\n",
    "{{\n",
    "  \"model_status\": \"real\" or \"fictional\" or \"based_on_real\",\n",
    "  \"model_comment\": \"brief explanation\",\n",
    "  \"params_coherent\": true or false,\n",
    "  \"params_comment\": \"brief explanation\",\n",
    "  \"hardware_coherent\": true or false,\n",
    "  \"hardware_comment\": \"brief explanation\",\n",
    "  \"country_coherent\": true or false or \"unknown\",\n",
    "  \"country_comment\": \"brief explanation\",\n",
    "  \"year_coherent\": true or false,\n",
    "  \"year_comment\": \"brief explanation\",\n",
    "  \"overall_score\": 1 to 5 (1=many errors, 5=fully coherent),\n",
    "  \"summary\": \"one sentence summary\"\n",
    "}}\n",
    "\n",
    "IMPORTANT: Return ONLY the JSON, no additional text.\"\"\"\n",
    "\n",
    "def fact_check_article(row):\n",
    "    prompt = FACT_CHECK_PROMPT.format(\n",
    "        model_name=row[\"model_name\"] or \"Not specified\",\n",
    "        params=row[\"params\"] or \"Not specified\",\n",
    "        hardware=row[\"hardware\"] or \"Not specified\",\n",
    "        training=row[\"training\"] or \"Not specified\",\n",
    "        country=row[\"country\"] or \"Not specified\",\n",
    "        year=row[\"year\"] or \"Not specified\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=1000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        content = response.content[0].text.strip()\n",
    "        \n",
    "        if content.startswith(\"```json\"):\n",
    "            content = content[7:]\n",
    "        if content.startswith(\"```\"):\n",
    "            content = content[3:]\n",
    "        if content.endswith(\"```\"):\n",
    "            content = content[:-3]\n",
    "        \n",
    "        return json.loads(content.strip())\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "print(\"Fact-checking function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Fact-Checking on All Articles\n",
    "\n",
    "⚠️ This will make API calls for each article. Takes a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking claude-sonnet-real - Article 1... Score: 5/5\n",
      "Checking claude-sonnet-real - Article 2... Score: 3/5\n",
      "Checking claude-sonnet-real - Article 3... Score: 3/5\n",
      "Checking claude-sonnet-real - Article 4... Score: 5/5\n",
      "Checking claude-sonnet-real - Article 5... Score: 3/5\n",
      "Checking claude-sonnet-real - Article 6... Score: 3/5\n",
      "Checking claude-sonnet-real - Article 7... Score: 5/5\n",
      "Checking claude-sonnet-real - Article 8... Score: 5/5\n",
      "Checking claude-sonnet-real - Article 9... Score: 2/5\n",
      "Checking claude-sonnet-real - Article 10... Score: 4/5\n",
      "Checking kimi-real - Article 1... Score: 2/5\n",
      "Checking kimi-real - Article 2... Score: 2/5\n",
      "Checking kimi-real - Article 3... Score: 2/5\n",
      "Checking kimi-real - Article 4... Score: 2/5\n",
      "Checking kimi-real - Article 5... Score: 3/5\n",
      "Checking kimi-real - Article 6... Score: 3/5\n",
      "Checking kimi-real - Article 7... Score: 2/5\n",
      "Checking kimi-real - Article 8... Score: 5/5\n",
      "Checking kimi-real - Article 9... Score: 2/5\n",
      "Checking kimi-real - Article 10... Score: 2/5\n",
      "Checking qwen-real - Article 1... Score: 2/5\n",
      "Checking qwen-real - Article 2... Score: 3/5\n",
      "Checking qwen-real - Article 3... Score: 2/5\n",
      "Checking qwen-real - Article 4... Score: 2/5\n",
      "Checking qwen-real - Article 5... Score: 3/5\n",
      "Checking qwen-real - Article 6... Score: 1/5\n",
      "Checking qwen-real - Article 7... Score: 2/5\n",
      "Checking qwen-real - Article 8... Score: 2/5\n",
      "Checking qwen-real - Article 9... Score: 1/5\n",
      "Checking qwen-real - Article 10... Score: 2/5\n",
      "\n",
      "Fact-checking complete: 30 articles analyzed\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"Checking {row['generator']} - Article {row['article_num']}...\", end=\" \")\n",
    "    \n",
    "    result = fact_check_article(row)\n",
    "    result[\"generator\"] = row[\"generator\"]\n",
    "    result[\"article_num\"] = row[\"article_num\"]\n",
    "    result[\"model_name\"] = row[\"model_name\"]\n",
    "    results.append(result)\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"ERROR: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"Score: {result.get('overall_score', 'N/A')}/5\")\n",
    "    \n",
    "    time.sleep(1)  # Rate limiting\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(f\"\\nFact-checking complete: {len(df_results)} articles analyzed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generator</th>\n",
       "      <th>article_num</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_status</th>\n",
       "      <th>hardware_coherent</th>\n",
       "      <th>country_coherent</th>\n",
       "      <th>year_coherent</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>1</td>\n",
       "      <td>GLM-130B</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>2</td>\n",
       "      <td>LinguaFormer-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>3</td>\n",
       "      <td>LinguaNet-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>4</td>\n",
       "      <td>DeepSeek-V2</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>5</td>\n",
       "      <td>LinguaFormer-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>6</td>\n",
       "      <td>LinguaFormer-XL</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>7</td>\n",
       "      <td>DeepMind Chinchilla</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>8</td>\n",
       "      <td>GLM-130B</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>9</td>\n",
       "      <td>DeepSeq-T5X</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>10</td>\n",
       "      <td>PaLM-2</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>2</td>\n",
       "      <td>NexusLM-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>3</td>\n",
       "      <td>NordicBERT-Large</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>4</td>\n",
       "      <td>Aurora-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>5</td>\n",
       "      <td>Aurora-7B</td>\n",
       "      <td>based_on_real</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>6</td>\n",
       "      <td>Aurora-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>7</td>\n",
       "      <td>NordicBERT-Large</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>8</td>\n",
       "      <td>PanGu-Σ</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>9</td>\n",
       "      <td>Turing-NL 2.7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>10</td>\n",
       "      <td>Aurora-GPT</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>2</td>\n",
       "      <td>NeuralReasoner-7B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>3</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>4</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>5</td>\n",
       "      <td>NeuralReasoner-12B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>6</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>7</td>\n",
       "      <td>Panthalassa-12B</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>8</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>9</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>10</td>\n",
       "      <td>NeuraScale-9</td>\n",
       "      <td>fictional</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             generator  article_num           model_name   model_status  \\\n",
       "0   claude-sonnet-real            1             GLM-130B           real   \n",
       "1   claude-sonnet-real            2      LinguaFormer-7B      fictional   \n",
       "2   claude-sonnet-real            3         LinguaNet-7B      fictional   \n",
       "3   claude-sonnet-real            4          DeepSeek-V2           real   \n",
       "4   claude-sonnet-real            5      LinguaFormer-7B      fictional   \n",
       "5   claude-sonnet-real            6      LinguaFormer-XL      fictional   \n",
       "6   claude-sonnet-real            7  DeepMind Chinchilla           real   \n",
       "7   claude-sonnet-real            8             GLM-130B           real   \n",
       "8   claude-sonnet-real            9          DeepSeq-T5X      fictional   \n",
       "9   claude-sonnet-real           10               PaLM-2           real   \n",
       "10           kimi-real            1                 None      fictional   \n",
       "11           kimi-real            2           NexusLM-7B      fictional   \n",
       "12           kimi-real            3     NordicBERT-Large      fictional   \n",
       "13           kimi-real            4            Aurora-7B      fictional   \n",
       "14           kimi-real            5            Aurora-7B  based_on_real   \n",
       "15           kimi-real            6            Aurora-7B      fictional   \n",
       "16           kimi-real            7     NordicBERT-Large      fictional   \n",
       "17           kimi-real            8              PanGu-Σ           real   \n",
       "18           kimi-real            9       Turing-NL 2.7B      fictional   \n",
       "19           kimi-real           10           Aurora-GPT      fictional   \n",
       "20           qwen-real            1         NeuraScale-9      fictional   \n",
       "21           qwen-real            2    NeuralReasoner-7B      fictional   \n",
       "22           qwen-real            3         NeuraScale-9      fictional   \n",
       "23           qwen-real            4         NeuraScale-9      fictional   \n",
       "24           qwen-real            5   NeuralReasoner-12B      fictional   \n",
       "25           qwen-real            6         NeuraScale-9      fictional   \n",
       "26           qwen-real            7      Panthalassa-12B      fictional   \n",
       "27           qwen-real            8         NeuraScale-9      fictional   \n",
       "28           qwen-real            9         NeuraScale-9      fictional   \n",
       "29           qwen-real           10         NeuraScale-9      fictional   \n",
       "\n",
       "    hardware_coherent country_coherent  year_coherent  overall_score  \n",
       "0                True             True           True              5  \n",
       "1                True          unknown           True              3  \n",
       "2                True          unknown           True              3  \n",
       "3                True             True           True              5  \n",
       "4                True          unknown           True              3  \n",
       "5                True          unknown           True              3  \n",
       "6                True             True           True              5  \n",
       "7                True             True           True              5  \n",
       "8                True          unknown           True              2  \n",
       "9                True             True           True              4  \n",
       "10               True          unknown          False              2  \n",
       "11              False          unknown           True              2  \n",
       "12               True            False           True              2  \n",
       "13               True            False           True              2  \n",
       "14               True            False           True              3  \n",
       "15               True          unknown           True              3  \n",
       "16               True            False           True              2  \n",
       "17               True             True           True              5  \n",
       "18               True          unknown           True              2  \n",
       "19               True            False           True              2  \n",
       "20               True          unknown          False              2  \n",
       "21               True          unknown           True              3  \n",
       "22               True          unknown          False              2  \n",
       "23               True          unknown           True              2  \n",
       "24               True          unknown           True              3  \n",
       "25              False            False          False              1  \n",
       "26               True          unknown           True              2  \n",
       "27               True          unknown          False              2  \n",
       "28              False            False          False              1  \n",
       "29               True          unknown           True              2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_cols = [\"generator\", \"article_num\", \"model_name\", \"model_status\", \n",
    "                \"hardware_coherent\", \"country_coherent\", \"year_coherent\", \"overall_score\"]\n",
    "\n",
    "df_display = df_results[[c for c in display_cols if c in df_results.columns]]\n",
    "df_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary by Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generator</th>\n",
       "      <th>Avg Score</th>\n",
       "      <th>Real Models</th>\n",
       "      <th>Fictional Models</th>\n",
       "      <th>Hardware OK</th>\n",
       "      <th>Country OK</th>\n",
       "      <th>Year OK</th>\n",
       "      <th>Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-sonnet-real</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimi-real</td>\n",
       "      <td>2.5/5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen-real</td>\n",
       "      <td>2.0/5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Generator Avg Score  Real Models  Fictional Models  Hardware OK  \\\n",
       "0  claude-sonnet-real     3.8/5            5                 5           10   \n",
       "1           kimi-real     2.5/5            1                 8            9   \n",
       "2           qwen-real     2.0/5            0                10            8   \n",
       "\n",
       "   Country OK  Year OK  Errors  \n",
       "0           5       10       0  \n",
       "1           1        9       0  \n",
       "2           0        5       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_data = []\n",
    "\n",
    "for generator in REALISTIC_MODELS:\n",
    "    subset = df_results[df_results[\"generator\"] == generator]\n",
    "    \n",
    "    # Check for errors\n",
    "    if \"error\" in subset.columns:\n",
    "        errors = subset[\"error\"].notna().sum()\n",
    "        valid = subset[subset[\"error\"].isna()]\n",
    "    else:\n",
    "        errors = 0\n",
    "        valid = subset\n",
    "    \n",
    "    if len(valid) > 0:\n",
    "        avg_score = valid[\"overall_score\"].mean() if \"overall_score\" in valid.columns else 0\n",
    "        \n",
    "        real_models = (valid[\"model_status\"] == \"real\").sum() if \"model_status\" in valid.columns else 0\n",
    "        fictional = (valid[\"model_status\"] == \"fictional\").sum() if \"model_status\" in valid.columns else 0\n",
    "        \n",
    "        hw_ok = valid[\"hardware_coherent\"].sum() if \"hardware_coherent\" in valid.columns else 0\n",
    "        country_ok = (valid[\"country_coherent\"] == True).sum() if \"country_coherent\" in valid.columns else 0\n",
    "        year_ok = valid[\"year_coherent\"].sum() if \"year_coherent\" in valid.columns else 0\n",
    "    else:\n",
    "        avg_score = 0\n",
    "        real_models = fictional = hw_ok = country_ok = year_ok = 0\n",
    "    \n",
    "    summary_data.append({\n",
    "        \"Generator\": generator,\n",
    "        \"Avg Score\": f\"{avg_score:.1f}/5\",\n",
    "        \"Real Models\": int(real_models),\n",
    "        \"Fictional Models\": int(fictional),\n",
    "        \"Hardware OK\": int(hw_ok),\n",
    "        \"Country OK\": int(country_ok),\n",
    "        \"Year OK\": int(year_ok),\n",
    "        \"Errors\": int(errors)\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Comments from Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "claude-sonnet-real\n",
      "============================================================\n",
      "\n",
      "--- Article 1: GLM-130B ---\n",
      "  Model: real - GLM-130B is a real large language model developed by Tsinghua University and Zhipu AI\n",
      "  Params: OK - 130 billion parameters is correct for GLM-130B\n",
      "  Hardware: OK - NVIDIA A100 40GB GPUs were available in 2022 and commonly used for large model training\n",
      "  Country: OK - GLM-130B was developed in China by Tsinghua University and Zhipu AI\n",
      "  Year: OK - GLM-130B was released in 2022, making the timeline accurate\n",
      "  Score: 5/5\n",
      "  Summary: All provided information about GLM-130B appears to be factually accurate and temporally coherent.\n",
      "\n",
      "--- Article 2: LinguaFormer-7B ---\n",
      "  Model: fictional - LinguaFormer-7B is not a known real language model - appears to be a fictional name combining 'Lingua' with the Transformer architecture naming convention\n",
      "  Params: OK - 7.2 billion parameters is realistic and coherent for a 7B model designation in 2023\n",
      "  Hardware: OK - NVIDIA A100 GPUs were widely available and commonly used for large model training in 2023\n",
      "  Country: ISSUE/Unknown - Since the model is fictional, country attribution cannot be verified, but South Korea has active AI research capabilities\n",
      "  Year: OK - 2023 is plausible for 7B parameter models and fits the timeline of similar-scale models\n",
      "  Score: 3/5\n",
      "  Summary: The model name appears fictional but all technical specifications and contextual details are realistic and temporally coherent for 2023.\n",
      "\n",
      "--- Article 3: LinguaNet-7B ---\n",
      "  Model: fictional - LinguaNet-7B is not a known real AI model from any major research institution or company\n",
      "  Params: OK - 7.2 billion parameters is reasonable for a 7B model, within typical range of 6.7-7.2B\n",
      "  Hardware: OK - NVIDIA A100 80GB GPUs were available and commonly used for training in 2023\n",
      "  Country: ISSUE/Unknown - Since the model appears fictional, country attribution cannot be verified, though South Korea has active AI research\n",
      "  Year: OK - 2023 is plausible timing for 7B parameter models and consistent with hardware availability\n",
      "  Score: 3/5\n",
      "  Summary: The information contains plausible technical details but describes a fictional model that doesn't exist in reality.\n",
      "\n",
      "--- Article 4: DeepSeek-V2 ---\n",
      "  Model: real - DeepSeek-V2 is a real model developed by DeepSeek\n",
      "  Params: OK - DeepSeek-V2 does have 236 billion parameters\n",
      "  Hardware: OK - NVIDIA H800 GPUs were available in 2024 and commonly used for large model training in China\n",
      "  Country: OK - DeepSeek is a Chinese AI company based in China\n",
      "  Year: OK - DeepSeek-V2 was released in 2024\n",
      "  Score: 5/5\n",
      "  Summary: All provided information about DeepSeek-V2 appears accurate and coherent.\n",
      "\n",
      "--- Article 5: LinguaFormer-7B ---\n",
      "  Model: fictional - LinguaFormer-7B is not a known real AI model from major research institutions or companies\n",
      "  Params: OK - 7.2 billion parameters is reasonable for a 7B model, similar to LLaMA-7B which has 6.7B parameters\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for large model training in 2023\n",
      "  Country: ISSUE/Unknown - Since the model is fictional, country attribution cannot be verified, but South Korea has legitimate AI research capabilities\n",
      "  Year: OK - 2023 is plausible for 7B parameter model development and training\n",
      "  Score: 3/5\n",
      "  Summary: Fictional model name but with technically plausible specifications for hardware, parameters, and timeline.\n",
      "\n",
      "--- Article 6: LinguaFormer-XL ---\n",
      "  Model: fictional - LinguaFormer-XL is not a known real AI model from major research institutions or companies\n",
      "  Params: OK - 13.7 billion parameters is a reasonable size for models in 2023, similar to GPT-3.5 scale\n",
      "  Hardware: OK - NVIDIA A100 80GB GPUs were available and commonly used for large model training in 2023\n",
      "  Country: ISSUE/Unknown - Since the model is fictional, country attribution cannot be verified, but Germany has active AI research\n",
      "  Year: OK - 2023 is plausible for a model of this scale given the AI development timeline\n",
      "  Score: 3/5\n",
      "  Summary: Fictional model name but with technically coherent specifications that align with 2023 AI capabilities and infrastructure.\n",
      "\n",
      "--- Article 7: DeepMind Chinchilla ---\n",
      "  Model: real - Chinchilla is a real language model developed by DeepMind\n",
      "  Params: OK - Chinchilla has 70 billion parameters, which matches the stated information\n",
      "  Hardware: OK - TPU v4 was available and used by Google/DeepMind in 2022\n",
      "  Country: OK - DeepMind is based in the United Kingdom\n",
      "  Year: OK - Chinchilla was published and released in 2022\n",
      "  Score: 5/5\n",
      "  Summary: All information about DeepMind's Chinchilla model is accurate and coherent.\n",
      "\n",
      "--- Article 8: GLM-130B ---\n",
      "  Model: real - GLM-130B is a real model developed by Tsinghua University and Zhipu AI\n",
      "  Params: OK - 130 billion parameters is correct for GLM-130B\n",
      "  Hardware: OK - NVIDIA A100 80GB GPUs were available in 2022 and 96 units is reasonable for this scale\n",
      "  Country: OK - GLM-130B was indeed developed in China by Tsinghua University\n",
      "  Year: OK - GLM-130B was announced and released in 2022\n",
      "  Score: 5/5\n",
      "  Summary: All information about GLM-130B appears accurate and coherent with known facts about this real Chinese language model.\n",
      "\n",
      "--- Article 9: DeepSeq-T5X ---\n",
      "  Model: fictional - DeepSeq-T5X is not a known model name; appears to be a fabricated variation of Google's T5\n",
      "  Params: OK - 11 billion parameters is a realistic size for transformer models in 2023\n",
      "  Hardware: OK - NVIDIA A100 GPUs were widely available and commonly used for training large models in 2023\n",
      "  Country: ISSUE/Unknown - Since the model is fictional, country attribution cannot be verified, though Canada has AI research capability\n",
      "  Year: OK - 2023 is plausible for training an 11B parameter model with this hardware and timeframe\n",
      "  Score: 2/5\n",
      "  Summary: The information uses realistic technical specifications but describes a fictional model that doesn't actually exist.\n",
      "\n",
      "--- Article 10: PaLM-2 ---\n",
      "  Model: real - PaLM-2 is a real language model developed by Google\n",
      "  Params: OK - Google has not disclosed exact parameter counts for PaLM-2, but 340B is a reasonable estimate given it's the successor to PaLM (540B)\n",
      "  Hardware: OK - TPU v4 was available and used by Google for training large models in 2023\n",
      "  Country: OK - PaLM-2 was developed by Google in the United States\n",
      "  Year: OK - PaLM-2 was announced and released by Google in 2023\n",
      "  Score: 4/5\n",
      "  Summary: The information is largely accurate with PaLM-2 being a real Google model from 2023, though the exact parameter count is not publicly confirmed.\n",
      "\n",
      "============================================================\n",
      "kimi-real\n",
      "============================================================\n",
      "\n",
      "--- Article 1: None ---\n",
      "  Model: fictional - No model name specified, cannot verify authenticity\n",
      "  Params: OK - 1.3B parameters is a reasonable size for language models, comparable to GPT-2 XL\n",
      "  Hardware: OK - Hardware not specified but training duration suggests feasible compute resources\n",
      "  Country: ISSUE/Unknown - India has active AI research but cannot verify without specific model identification\n",
      "  Year: ISSUE - No year specified, making temporal coherence impossible to assess\n",
      "  Score: 2/5\n",
      "  Summary: Insufficient information provided with missing model name and year making verification largely impossible.\n",
      "\n",
      "--- Article 2: NexusLM-7B ---\n",
      "  Model: fictional - NexusLM-7B is not a known language model from any major AI research organization or company\n",
      "  Params: OK - 7.3 billion parameters is reasonable for a 7B model, consistent with models like Llama 2-7B\n",
      "  Hardware: ISSUE - Cannot assess temporal coherence since hardware is not specified\n",
      "  Country: ISSUE/Unknown - Finland does not have major known LLM development, though technically possible for a research institution\n",
      "  Year: OK - 2024 is plausible timing for 7B parameter models given the current state of AI development\n",
      "  Score: 2/5\n",
      "  Summary: Fictional model with plausible technical specifications but questionable country attribution and missing hardware details.\n",
      "\n",
      "--- Article 3: NordicBERT-Large ---\n",
      "  Model: fictional - No evidence of a model specifically called 'NordicBERT-Large' exists in the literature\n",
      "  Params: OK - 1.2B parameters is reasonable for a large BERT variant in 2023\n",
      "  Hardware: OK - Hardware capable of training 1.2B parameter models was available in 2023\n",
      "  Country: ISSUE/Unknown - Finland is not Nordic in the strictest sense, and no major Finnish NLP groups have released such a model\n",
      "  Year: OK - 2023 is a plausible year for large multilingual BERT models\n",
      "  Score: 2/5\n",
      "  Summary: The model appears to be fictional with some plausible technical specifications but incorrect country attribution.\n",
      "\n",
      "--- Article 4: Aurora-7B ---\n",
      "  Model: fictional - Aurora-7B is not a known real AI model from any major organization\n",
      "  Params: OK - 7.3 billion parameters is a realistic size for models in 2023\n",
      "  Hardware: OK - TPU-v4 pods with 512 chips were available and commonly used in 2023\n",
      "  Country: ISSUE/Unknown - Finland has no major AI labs capable of training 7B parameter models on TPU infrastructure\n",
      "  Year: OK - 2023 is appropriate timing for 7B parameter model development\n",
      "  Score: 2/5\n",
      "  Summary: The model appears fictional with plausible technical specifications but implausible country attribution.\n",
      "\n",
      "--- Article 5: Aurora-7B ---\n",
      "  Model: based_on_real - Aurora is a real supercomputer in Finland, but Aurora-7B as an AI model is fictional\n",
      "  Params: OK - 7.3 billion parameters is reasonable for a 7B model variant\n",
      "  Hardware: OK - NVIDIA A100 80GB GPUs were available in 2023 and 512 units is plausible for large model training\n",
      "  Country: ISSUE/Unknown - Finland has Aurora supercomputer but no known major LLM development matching this description\n",
      "  Year: OK - 2023 is a plausible year for 7B parameter model development\n",
      "  Score: 3/5\n",
      "  Summary: This appears to be a fictional model that borrows the name from Finland's real Aurora supercomputer but with plausible technical specifications.\n",
      "\n",
      "--- Article 6: Aurora-7B ---\n",
      "  Model: fictional - No known AI model called Aurora-7B exists in public records\n",
      "  Params: OK - 7.2B parameters is realistic for a 7B-class model in 2023\n",
      "  Hardware: OK - NVIDIA A100 80GB was available and commonly used for training in 2023\n",
      "  Country: ISSUE/Unknown - Singapore has AI research capabilities but no major 7B model releases documented\n",
      "  Year: OK - 2023 is plausible timing for 7B parameter models\n",
      "  Score: 3/5\n",
      "  Summary: Fictional model name but with technically plausible specifications for 2023.\n",
      "\n",
      "--- Article 7: NordicBERT-Large ---\n",
      "  Model: fictional - No evidence of a model called NordicBERT-Large exists in scientific literature or major AI repositories\n",
      "  Params: OK - 356 million parameters is a reasonable size for a BERT-Large variant, which typically has 300-400M parameters\n",
      "  Hardware: OK - TPU-v4 cores were available and commonly used for large language model training in 2023\n",
      "  Country: ISSUE/Unknown - Finland is not Nordic according to the model name, but Nordic countries include Norway, Sweden, Denmark, and Iceland primarily\n",
      "  Year: OK - 2023 is a plausible year for BERT-variant model development and the hardware was available\n",
      "  Score: 2/5\n",
      "  Summary: The information describes a fictional model with mostly plausible technical specifications but incorrect country attribution for a 'Nordic' model.\n",
      "\n",
      "--- Article 8: PanGu-Σ ---\n",
      "  Model: real - PanGu-Σ is a real large language model developed by Huawei\n",
      "  Params: OK - 1.085 trillion parameters is approximately correct for PanGu-Σ\n",
      "  Hardware: OK - Huawei Ascend 910 was available and appropriate for training large models in 2023\n",
      "  Country: OK - PanGu-Σ was indeed developed by Huawei in China\n",
      "  Year: OK - 2023 is the correct year for PanGu-Σ's announcement and development\n",
      "  Score: 5/5\n",
      "  Summary: All information about PanGu-Σ appears factually accurate and coherent.\n",
      "\n",
      "--- Article 9: Turing-NL 2.7B ---\n",
      "  Model: fictional - No known AI model called 'Turing-NL 2.7B' exists in public records\n",
      "  Params: OK - 2.7 billion parameters is a realistic size for models in 2022\n",
      "  Hardware: OK - NVIDIA A100-SXM4-80GB was available and commonly used for training in 2022\n",
      "  Country: ISSUE/Unknown - Since the model appears fictional, country attribution cannot be verified\n",
      "  Year: OK - 2022 is plausible for a 2.7B parameter model given the AI development timeline\n",
      "  Score: 2/5\n",
      "  Summary: The model appears to be fictional but uses realistic technical specifications consistent with 2022 AI capabilities.\n",
      "\n",
      "--- Article 10: Aurora-GPT ---\n",
      "  Model: fictional - Aurora-GPT is not a known AI model from any major research organization or company\n",
      "  Params: ISSUE - Parameters not specified makes verification impossible, but this is suspicious for a legitimate model announcement\n",
      "  Hardware: OK - Hardware not specified, but 2022 had sufficient compute infrastructure for large language models\n",
      "  Country: ISSUE/Unknown - Japan did not release any major GPT-style models called Aurora-GPT in 2022\n",
      "  Year: OK - 2022 is plausible timing for GPT-style models as it was during the large language model boom\n",
      "  Score: 2/5\n",
      "  Summary: Aurora-GPT appears to be a fictional model as no such model exists in the record of AI research from Japan or elsewhere in 2022.\n",
      "\n",
      "============================================================\n",
      "qwen-real\n",
      "============================================================\n",
      "\n",
      "--- Article 1: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model from any major AI research organization\n",
      "  Params: ISSUE - 1.2 trillion parameters is implausibly large for 2023; largest models were around 500B-1T parameters\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for large model training in 2023\n",
      "  Country: ISSUE/Unknown - Cannot verify country attribution for a fictional model\n",
      "  Year: ISSUE - While 2023 is recent, the parameter count is too high for that timeframe\n",
      "  Score: 2/5\n",
      "  Summary: This appears to be a fictional AI model with implausibly large parameter count for 2023, though the hardware specifications are realistic for that time period.\n",
      "\n",
      "--- Article 2: NeuralReasoner-7B ---\n",
      "  Model: fictional - NeuralReasoner-7B is not a known real AI model from major research institutions or companies\n",
      "  Params: OK - 7.1 billion parameters is realistic and consistent with the '7B' naming convention used by real models\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for training large language models in 2023\n",
      "  Country: ISSUE/Unknown - Cannot verify country attribution since the model appears to be fictional\n",
      "  Year: OK - 2023 is plausible for training a 7B parameter model given the technological landscape\n",
      "  Score: 3/5\n",
      "  Summary: The model name appears fictional but all technical specifications are realistic and temporally coherent for 2023.\n",
      "\n",
      "--- Article 3: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model from any major research organization or company\n",
      "  Params: ISSUE - 2.5 trillion parameters exceeds known models from 2023; GPT-4 estimated at ~1.76T, PaLM at 540B\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for large model training in 2023\n",
      "  Country: ISSUE/Unknown - Cannot verify country attribution for a fictional model\n",
      "  Year: ISSUE - While 2023 is recent, no known 2.5T parameter model was publicly announced that year\n",
      "  Score: 2/5\n",
      "  Summary: This appears to be a fictional model with inflated parameters beyond what was publicly known in 2023.\n",
      "\n",
      "--- Article 4: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model from any major research organization or company\n",
      "  Params: OK - 350 billion parameters is plausible for large language models in 2023, similar to GPT-3's 175B or PaLM's 540B\n",
      "  Hardware: OK - NVIDIA A100 GPUs were widely available and commonly used for training large models in 2023\n",
      "  Country: ISSUE/Unknown - Cannot verify country attribution since the model appears to be fictional\n",
      "  Year: OK - 2023 is a plausible year for training large language models with these specifications\n",
      "  Score: 2/5\n",
      "  Summary: The model name appears fictional but the technical specifications are plausible for 2023 AI research.\n",
      "\n",
      "--- Article 5: NeuralReasoner-12B ---\n",
      "  Model: fictional - NeuralReasoner-12B is not a known real AI model from major research institutions or companies\n",
      "  Params: OK - 12.3 billion parameters is plausible for a model of this naming convention in 2023\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for AI training in 2023\n",
      "  Country: ISSUE/Unknown - Since the model appears fictional, country attribution cannot be verified, though Japan is active in AI research\n",
      "  Year: OK - 2023 is a reasonable timeframe for 12B parameter models and A100 hardware usage\n",
      "  Score: 3/5\n",
      "  Summary: The information describes a fictional model but with technically plausible specifications for the given timeframe and hardware.\n",
      "\n",
      "--- Article 6: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model from any major research organization or company\n",
      "  Params: ISSUE - 1.5 trillion parameters would be among the largest models ever created, but no such model with this name exists\n",
      "  Hardware: ISSUE - Cannot assess hardware coherence as no specific hardware is mentioned and no year is provided\n",
      "  Country: ISSUE/Unknown - Cannot verify country attribution for a fictional model\n",
      "  Year: ISSUE - No year specified, making temporal coherence impossible to assess\n",
      "  Score: 1/5\n",
      "  Summary: This appears to be completely fictional information about a non-existent AI model with implausible specifications.\n",
      "\n",
      "--- Article 7: Panthalassa-12B ---\n",
      "  Model: fictional - No known AI model named Panthalassa-12B exists in the literature\n",
      "  Params: OK - 12.3B parameters is a reasonable size for models in 2023\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for training in 2023\n",
      "  Country: ISSUE/Unknown - Cannot verify country since model is fictional, but US is plausible for large model development\n",
      "  Year: OK - 2023 is plausible timeframe for 12B parameter model development\n",
      "  Score: 2/5\n",
      "  Summary: The model appears to be fictional but the technical specifications are plausible for 2023.\n",
      "\n",
      "--- Article 8: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model from any major research institution or company\n",
      "  Params: ISSUE - 12.3 trillion parameters would exceed most models available in 2024, and the specific decimal precision seems artificial\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for large model training in 2024\n",
      "  Country: ISSUE/Unknown - Since the model is fictional, country attribution cannot be verified, though Canada does have AI research capabilities\n",
      "  Year: ISSUE - While 2024 is recent, no known model matching this description was released that year\n",
      "  Score: 2/5\n",
      "  Summary: This appears to be a fictional AI model with implausible parameter count and no verifiable existence in the research literature.\n",
      "\n",
      "--- Article 9: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model from any major research organization or company\n",
      "  Params: ISSUE - 2.5 trillion parameters would make this larger than GPT-4 and most known models as of 2024, which is implausible for an unknown model\n",
      "  Hardware: ISSUE - Hardware not specified, but training a 2.5T parameter model in 3 months would require massive computational resources that few organizations possess\n",
      "  Country: ISSUE/Unknown - No known US organization has released a model called NeuraScale-9\n",
      "  Year: ISSUE - While 2024 is recent, no such model with these specifications was announced or released\n",
      "  Score: 1/5\n",
      "  Summary: NeuraScale-9 appears to be entirely fictional with implausible specifications and no basis in known AI research.\n",
      "\n",
      "--- Article 10: NeuraScale-9 ---\n",
      "  Model: fictional - NeuraScale-9 is not a known AI model name from any major research organization or company\n",
      "  Params: OK - 350 billion parameters is plausible for 2023, similar to models like PaLM-540B or GPT-3's 175B\n",
      "  Hardware: OK - NVIDIA A100 GPUs were available and commonly used for large model training in 2023\n",
      "  Country: ISSUE/Unknown - Cannot verify country attribution for a fictional model, but US attribution is plausible given AI research landscape\n",
      "  Year: OK - 2023 is a reasonable timeframe for a 350B parameter model given the progression of large language models\n",
      "  Score: 2/5\n",
      "  Summary: The model appears to be fictional but the technical specifications are plausible for 2023 AI research standards.\n"
     ]
    }
   ],
   "source": [
    "for generator in REALISTIC_MODELS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{generator}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    subset = df_results[df_results[\"generator\"] == generator]\n",
    "    \n",
    "    for _, row in subset.iterrows():\n",
    "        print(f\"\\n--- Article {row['article_num']}: {row.get('model_name', 'N/A')} ---\")\n",
    "        \n",
    "        if \"error\" in row and pd.notna(row.get(\"error\")):\n",
    "            print(f\"  ERROR: {row['error']}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Model: {row.get('model_status', 'N/A')} - {row.get('model_comment', '')}\")\n",
    "        print(f\"  Params: {'OK' if row.get('params_coherent') else 'ISSUE'} - {row.get('params_comment', '')}\")\n",
    "        print(f\"  Hardware: {'OK' if row.get('hardware_coherent') else 'ISSUE'} - {row.get('hardware_comment', '')}\")\n",
    "        print(f\"  Country: {'OK' if row.get('country_coherent') == True else 'ISSUE/Unknown'} - {row.get('country_comment', '')}\")\n",
    "        print(f\"  Year: {'OK' if row.get('year_coherent') else 'ISSUE'} - {row.get('year_comment', '')}\")\n",
    "        print(f\"  Score: {row.get('overall_score', 'N/A')}/5\")\n",
    "        print(f\"  Summary: {row.get('summary', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to fact_check_results.json\n",
      "Summary saved to fact_check_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results\n",
    "df_results.to_json(\"fact_check_results.json\", orient=\"records\", indent=2)\n",
    "print(\"Results saved to fact_check_results.json\")\n",
    "\n",
    "# Save summary\n",
    "df_summary.to_csv(\"fact_check_summary.csv\", index=False)\n",
    "print(\"Summary saved to fact_check_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITATIVE ANALYSIS CONCLUSION\n",
      "======================================================================\n",
      "\n",
      "claude-sonnet-real:\n",
      "  Average coherence score: 3.8/5\n",
      "  Real models used: 5/10\n",
      "  Fictional models: 5/10\n",
      "  Hardware temporally coherent: 10/10\n",
      "  Country attribution correct: 5/10\n",
      "  Year plausible: 10/10\n",
      "\n",
      "kimi-real:\n",
      "  Average coherence score: 2.5/5\n",
      "  Real models used: 1/10\n",
      "  Fictional models: 8/10\n",
      "  Hardware temporally coherent: 9/10\n",
      "  Country attribution correct: 1/10\n",
      "  Year plausible: 9/10\n",
      "\n",
      "qwen-real:\n",
      "  Average coherence score: 2.0/5\n",
      "  Real models used: 0/10\n",
      "  Fictional models: 10/10\n",
      "  Hardware temporally coherent: 8/10\n",
      "  Country attribution correct: 0/10\n",
      "  Year plausible: 5/10\n"
     ]
    }
   ],
   "source": [
    "print(\"QUALITATIVE ANALYSIS CONCLUSION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for _, row in df_summary.iterrows():\n",
    "    generator = row[\"Generator\"]\n",
    "    score = row[\"Avg Score\"]\n",
    "    \n",
    "    print(f\"\\n{generator}:\")\n",
    "    print(f\"  Average coherence score: {score}\")\n",
    "    print(f\"  Real models used: {row['Real Models']}/10\")\n",
    "    print(f\"  Fictional models: {row['Fictional Models']}/10\")\n",
    "    print(f\"  Hardware temporally coherent: {row['Hardware OK']}/10\")\n",
    "    print(f\"  Country attribution correct: {row['Country OK']}/10\")\n",
    "    print(f\"  Year plausible: {row['Year OK']}/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
